{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/grid-search-arima-hyperparameters-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-step sarima forecast\n",
    "def sarima_forecast(history, config):\n",
    "\torder, sorder, trend = config\n",
    "\t# define model\n",
    "\tmodel = sm.tsa.SARIMAX(history, order=order, \n",
    "                    seasonal_order=sorder, \n",
    "                    trend=trend, \n",
    "                    enforce_stationarity=False, \n",
    "                    enforce_invertibility=False)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(disp=False)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train and test set \n",
    "def split_train_test(data, train_size):\n",
    "    return data[0:train_size], data[train_size:len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse_socre(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The walk_forward_validation() function below taking a univariate time series, a number of time steps to use in the test set, and an array of model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(data, n_tests, cfg):\n",
    "    predictions=list()\n",
    "    train, test = split_train_test(data, n_tests)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for t in range(len(test)):\n",
    "        forecast_res = sarima_forecast(history=history, config=cfg)\n",
    "        predictions.append(forecast_res)\n",
    "        history.append(test[t])\n",
    "        \n",
    "    # estimate prediction error\n",
    "    rmse = get_rmse_socre(test, predicted=predictions)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of sarima configs to try\n",
    "def sarima_configs(seasonal=[0]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tp_params = [0, 1, 2]\n",
    "\td_params = [0, 1]\n",
    "\tq_params = [0, 1, 2]\n",
    "\tt_params = ['n','c','t','ct']\n",
    "\tP_params = [0, 1, 2]\n",
    "\tD_params = [0, 1]\n",
    "\tQ_params = [0, 1, 2]\n",
    "\tm_params = seasonal\n",
    "\t# create config instances\n",
    "\tfor p in p_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor q in q_params:\n",
    "\t\t\t\tfor t in t_params:\n",
    "\t\t\t\t\tfor P in P_params:\n",
    "\t\t\t\t\t\tfor D in D_params:\n",
    "\t\t\t\t\t\t\tfor Q in Q_params:\n",
    "\t\t\t\t\t\t\t\tfor m in m_params:\n",
    "\t\t\t\t\t\t\t\t\tcfg = [(p,d,q), (P,D,Q,m), t]\n",
    "\t\t\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 'n']] 76.920\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 'c']] 33.603\n",
      " > Model[[(0, 1, 0), (0, 0, 0, 0), 'n']] 10.000\n",
      " > Model[[(0, 1, 0), (0, 0, 0, 0), 't']] 5.512\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 't']] 6.383\n",
      " > Model[[(0, 1, 0), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(0, 0, 1), (0, 0, 0, 0), 'n']] 76.920 > Model[[(0, 0, 1), (0, 0, 0, 0), 'c']] 52.886\n",
      "\n",
      " > Model[[(0, 0, 1), (0, 0, 0, 0), 't']] 66.599\n",
      " > Model[[(0, 1, 1), (0, 0, 0, 0), 'n']] 8.948\n",
      " > Model[[(0, 1, 1), (0, 0, 0, 0), 'c']] 0.001\n",
      " > Model[[(0, 0, 0), (0, 0, 0, 0), 'ct']] 0.052 > Model[[(0, 0, 1), (0, 0, 0, 0), 'ct']] 1.322\n",
      "\n",
      " > Model[[(1, 0, 0), (0, 0, 0, 0), 'n']] 6.383\n",
      " > Model[[(0, 1, 1), (0, 0, 0, 0), 't']] 2.944\n",
      " > Model[[(1, 0, 0), (0, 0, 0, 0), 't']] 6.383 > Model[[(1, 0, 0), (0, 0, 0, 0), 'c']] 0.000\n",
      "\n",
      " > Model[[(1, 0, 0), (0, 0, 0, 0), 'ct']] 0.000\n",
      " > Model[[(1, 0, 1), (0, 0, 0, 0), 'n']] 3.980\n",
      " > Model[[(1, 0, 1), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(1, 1, 0), (0, 0, 0, 0), 'n']] 0.000\n",
      " > Model[[(1, 1, 0), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(1, 0, 1), (0, 0, 0, 0), 't']] 3.980\n",
      " > Model[[(1, 1, 0), (0, 0, 0, 0), 't']] 0.000\n",
      " > Model[[(1, 1, 0), (0, 0, 0, 0), 'ct']] 0.000\n",
      " > Model[[(0, 1, 0), (0, 0, 0, 0), 'ct']] 0.000\n",
      " > Model[[(1, 1, 1), (0, 0, 0, 0), 'n']] 0.000\n",
      " > Model[[(1, 0, 1), (0, 0, 0, 0), 'ct']] 0.303\n",
      " > Model[[(1, 1, 1), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(2, 0, 0), (0, 0, 0, 0), 'n']] 0.000\n",
      " > Model[[(1, 1, 1), (0, 0, 0, 0), 't']] 0.023\n",
      " > Model[[(2, 0, 0), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(1, 1, 1), (0, 0, 0, 0), 'ct']] 0.024\n",
      " > Model[[(0, 1, 1), (0, 0, 0, 0), 'ct']] 1.886\n",
      " > Model[[(2, 0, 1), (0, 0, 0, 0), 'n']] 0.001\n",
      " > Model[[(2, 0, 0), (0, 0, 0, 0), 't']] 0.000\n",
      " > Model[[(2, 0, 1), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(2, 1, 0), (0, 0, 0, 0), 'n']] 0.000\n",
      " > Model[[(2, 1, 0), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(2, 0, 0), (0, 0, 0, 0), 'ct']] 0.000\n",
      " > Model[[(2, 1, 0), (0, 0, 0, 0), 'ct']] 0.076 > Model[[(2, 1, 0), (0, 0, 0, 0), 't']] 0.019\n",
      "\n",
      " > Model[[(2, 1, 1), (0, 0, 0, 0), 'n']] 0.000\n",
      " > Model[[(2, 1, 1), (0, 0, 0, 0), 'c']] 0.000\n",
      " > Model[[(2, 1, 1), (0, 0, 0, 0), 'ct']] 0.104\n",
      " > Model[[(2, 0, 1), (0, 0, 0, 0), 'ct']] 0.002\n",
      " > Model[[(2, 1, 1), (0, 0, 0, 0), 't']] 0.059\n",
      " > Model[[(2, 0, 1), (0, 0, 0, 0), 't']] 0.000\n",
      "done\n",
      "[(1, 1, 0), (0, 0, 0, 0), 'c'] 2.9007785717557725e-15\n",
      "[(1, 1, 0), (0, 0, 0, 0), 'ct'] 7.105427357601002e-15\n",
      "[(2, 0, 0), (0, 0, 0, 0), 'c'] 1.5349477418661813e-14\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t# define dataset\n",
    "\tdata = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "\tprint(data)\n",
    "\t# data split\n",
    "\tn_test = 4\n",
    "\t# model configs\n",
    "\tcfg_list = sarima_configs()\n",
    "\t# grid search\n",
    "\tscores = grid_search(data, cfg_list, n_test)\n",
    "\tprint('done')\n",
    "\t# list top 3 configs\n",
    "\tfor cfg, error in scores[:3]:\n",
    "\t\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
