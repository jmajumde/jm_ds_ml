User name	Password	Access key ID			Secret access key							Console login link
ml_user		            AKIAS56446XY57UTMEB3	++AHdOFnF2QeN+5YX3ZBn1QvB+smqFdQPIDnMzsU	https://jmajumde-cloud-guru.signin.aws.amazon.com/console
ml_user_predict         AKIAS56446XYSSPHNUX4    PQDOrcUoP+uQBWcdiNqm3HQzZgTchL1/vh4nf6kf


sagemaker dev guide
-------------------
https://docs.aws.amazon.com/sagemaker/latest/dg/common-info-all-im-models.html

https://www.braincert.com/course/22419-AWS-Certified-Machine-Learning-%E2%80%93-Specialty-Practice-Exams#




---MLOps---
https://fall2019.fullstackdeeplearning.com/course-content/labs
https://www.coursera.org/learn/mlops-fundamentals


study guide pointers
--------------------
VVImp: https://tutorialsdojo.com/aws-certified-machine-learning-specialty-exam-study-path/
https://portal.tutorialsdojo.com/product/aws-certified-machine-learning-specialty-practice-exams/

Nuts and Bolts of Applying Deep Learning (Andrew Ng) -> https://www.youtube.com/watch?v=wjqaz6m42wU
https://www.linkedin.com/pulse/nuts-bolts-optimization-chandra-mohan-lingam/




==================== EDA/Data Engineering =======================
Athena
-------
https://tutorialsdojo.com/amazon-athena/
https://docs.aws.amazon.com/athena/latest/ug/what-is.html

https://medium.com/swlh/tutorial-build-your-data-lake-using-aws-s3-athena-150c1aaa44cf


AWS EMR Intro
-------------
https://tutorialsdojo.com/amazon-emr/
https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html

https://tutorialsdojo.com/aws-data-pipeline/
https://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/what-is-datapipeline.html

https://d1.awsstatic.com/whitepapers/Big_Data_Analytics_Options_on_AWS.pdf


- Apache Spark on Amazon EMR
- Apache Spark and Amazon SageMaker


Elasti search
-------------
https://tutorialsdojo.com/amazon-cloudsearch/

https://tutorialsdojo.com/amazon-elasticsearch-amazon-es/
https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/what-is-amazon-elasticsearch-service.html

Amazon Mechanical Turk
----------------------
https://tutorialsdojo.com/amazon-mechanical-turk/

Kinesis
--------
https://tutorialsdojo.com/amazon-kinesis/
https://docs.aws.amazon.com/streams/latest/dev/introduction.html
https://tutorialsdojo.com/kinesis-scaling-resharding-and-parallel-processing/


- Amazon Kinesis Data Streams
-> low latency streaming ingest at scale, user going to write custom code (producer/consumer)
-> Streams are divided in ordered Sherds /Partitions
-> Shards have to be provisioned in advanced (capacity planning)
-> Data retention (storage) 24hrs by default, can go upto 7 days
-> Ability to reprocess / reply data
-> Multiple applications can consume the same stream
-> once data is inserted in Kinesis, it can't be deleted (immutability)
-> Producer records can be upto 1MB in size at per shard, "ProvisionedThgoughputException"
-> Consumer 2MB/s at read per shard accross all consumers
-> 5 API calls per second per shard across all consumers
https://d1.awsstatic.com/whitepapers/whitepaper-streaming-data-solutions-on-aws-with-amazon-kinesis.pdf

- Amazon Kinesis Data Firehose
-> Data Ingestion (lad streams) into Redshift/Amazon S3/ElasticSearch/Splunk (kind of delivery service)
-> Fully managed service , no administration
-> near real time (60secs latency minimum for non full batches)
-> Auto scaling
-> Supports many data formats
-> Data conversions from CSV/Json to Parquet/ORC (only for S3)
-> Serverless data transformation through AWS Lambda (ex: CSV => JSON )
-> Supports compression when target is S3
-> Pay for the amount of data going through Firehose


- Amazon Kinesis Data Analytics
--> perform real-time analytics on streams using SQL
-> Streaming ETL: select columns, make simple transformations, on streaming data
-> Continues metric generation: live leaderboard for a mobile game
-> Responsive analytics: look for certain criterion and build alerting (filtering)
-> Pay only for resource consumed
-> Serverless; scale automatically
-> use IAM permissions to access streaming source and destination(s)
-> SQL or Flink to write the computation
-> Schema discovery
-> Lambda can be used for pre-processing

-> ML on Kinesis DA
--> RCF
---- SQL function used for anomaly detection on numeric columns in a stream
---- Uses recent history to compute model

--> HotSpots
---- locate and return information about relatively dense region on the data
---- Ex: a collection of overheated server in a datacenter


- Amazon Kinesis Video Streams
--> meant for streaming video in real-time
Producers:
-> security camera, body-worm camera, aws deeplens, smartphone camera, audio feeds, images, RADAR data, RTSP camera
-> One producer per video stream
-> video playing capability
Consumers:
-> build your own (MXNet, Tensorflow)
-> AWS SageMaker
-> Amazon Rekognition Video
Keep data for 1 hr to 10 yrs
https://aws.amazon.com/blogs/machine-learning/analyze-live-video-at-scale-in-real-time-using-amazon-kinesis-video-streams-and-amazon-sagemaker/
https://aws.amazon.com/blogs/machine-learning/improve-your-customer-service-using-amazon-kinesis-video-streams-and-amazon-rekognition-video/
https://aws.amazon.com/blogs/machine-learning/easily-perform-facial-analysis-on-live-feeds-by-creating-a-serverless-video-analytics-environment-with-amazon-rekognition-video-and-amazon-kinesis-video-streams/


- AWS Glue (Hive)
-> Glue data catalog is like Hive metastore
-> metadata repository for all tables
--> automated schema inference
--> schemas are versioned
-> Integrates with Athena or Redshift Spectrum (schema and data discovery)
-> Glue Crawlers can help build the Glue data catalog
-> Crawlers go through your data to infer schemas and partitions
-> Works JSON, Parquet, CSV, rational store
-> Crawlers works for S3, Redshift, RDS
-> Crawlers can be run scheduled or on demand
-> Need separate IAM role/credentials to access the data store


- AWS Glue ETL
-> Transform data, clean data, enrich data (before doing analysis)
--> generate ETL code in python or scala, you can modify code
--> can provide your own spark and PySpark scripts
--> Target can be S3, JDBC (RDS, Redshift) or in Glue data catalog
-> Fully managed, cost effective
-> Jobs are run on a serverless Spark platform
-> Glue scheduler to schedule the jobs
-> Glue Triggers to automate job runs based on "events"
-> Bundled Transformation:
	- DropFields, DropNullFields: remove (null) fields
	- Filter: specify a function to filter records
	- Join: to enrich data
	- Map: add fields, delete fields, perform external lookups
-> ML Transformation:
	- FindMatchesML: identity duplicate or matching records in your dataset, 
					 even when the records do not have a common unique identifier and 
					 no fields match exactly
-> Format coversions: CSV, JSON, Avro, Parquet, ORC, XML
-> Apache spark transformations (example: K-Means)



Working with stored videos:
https://docs.aws.amazon.com/rekognition/latest/dg/video.html

Lamda for stream-processing
---------------------------
https://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf


QuickSight
----------
https://tutorialsdojo.com/amazon-quicksight/

AWS Datalake
------------
S3 -> Athena -> Glue -> QuickSight
Tutorial: Creating a Data Lake from a JDBC Source in Lake Formation -> https://docs.aws.amazon.com/lake-formation/latest/dg/getting-started-tutorial.html

https://medium.com/swlh/tutorial-build-your-data-lake-using-aws-s3-athena-150c1aaa44cf


- AWS Lake formation
- Amazon S3 (as storage for a data lake)
- Amazon FSx for Lustre





================ GPU/Tensorflow machines ==================
Elastic Inference
-----------------
https://tutorialsdojo.com/amazon-elastic-inference/
https://docs.aws.amazon.com/elastic-inference/latest/developerguide/basics.html

====================================== NLP related more or less =====================
A2I
---
https://tutorialsdojo.com/amazon-augmented-ai-a2i/
https://docs.aws.amazon.com/textract/latest/dg/a2i-textract.html

Comrehend
---------
https://tutorialsdojo.com/amazon-comprehend/
https://docs.aws.amazon.com/comprehend/latest/dg/how-it-works.html

Lex
---
https://tutorialsdojo.com/amazon-lex/
https://docs.aws.amazon.com/lex/latest/dg/how-it-works.html

textract
---------
https://tutorialsdojo.com/amazon-textract/
https://docs.aws.amazon.com/textract/latest/dg/what-is.html
https://aws.amazon.com/blogs/machine-learning/using-amazon-textract-with-amazon-augmented-ai-for-processing-critical-documents/

Personalize
-----------
https://tutorialsdojo.com/amazon-personalize/
https://aws.amazon.com/blogs/machine-learning/using-a-b-testing-to-measure-the-efficacy-of-recommendations-generated-by-amazon-personalize/
https://aws.amazon.com/blogs/machine-learning/amazon-personalize-can-now-create-up-to-50-better-recommendations-for-fast-changing-catalogs-of-new-products-and-fresh-content/

Polly
-----
https://tutorialsdojo.com/amazon-polly/
https://docs.aws.amazon.com/polly/latest/dg/how-text-to-speech-works.html

Transcribe
----------
https://tutorialsdojo.com/amazon-transcribe/
https://docs.aws.amazon.com/transcribe/latest/dg/how-it-works.html

---lab---
https://jm-ml-sagemaker01.s3.ap-south-1.amazonaws.com/Transcribe/VocabularyList.txt
https://jm-ml-sagemaker01.s3.ap-south-1.amazonaws.com/Transcribe/VocabularyTable.txt
https://jm-ml-sagemaker01.s3.ap-south-1.amazonaws.com/Transcribe/XGBoost+Audio+Sample.wav

Translate
---------
https://tutorialsdojo.com/amazon-translate/
https://docs.aws.amazon.com/translate/latest/dg/what-is.html


Mechanical Turks (ground truth labeling)
----------------
https://blog.mturk.com/aws-introduces-a-new-way-to-label-data-for-machine-learning-with-mturk-2f9c19866a98
https://aws.amazon.com/sagemaker/groundtruth/

=================================== ML/DL relate dmore or less ===========================
SageMaker
---------
https://tutorialsdojo.com/amazon-sagemaker/
https://docs.aws.amazon.com/sagemaker/latest/dg/gs.html

sagemaker deep drive ->
https://www.youtube.com/watch?v=uQc8Itd4UTs&list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz


- Linear learner
- XGBoost
- Seq2Seq
- DeepAR
- BlazingText
- Object2Vec
- RandomCutForest
- NeuralTopicModel
- 

AWS marraige prediction age -> https://www.youtube.com/watch?v=sm5xeKal72I
https://github.com/ashokveda/ML_deployment_Flask_AWS_marriage_age_prediction


- SageMaker estimators
- SageMaker hyperparameter tuning jobs
- Common hyperparameters to tune:
Momentum
Optimizers
Activation functions
Dropout
Learning rate

- Regularization:
Dropout
L1/L2



Rekognition
------------
https://tutorialsdojo.com/amazon-rekognition/
https://docs.aws.amazon.com/rekognition/latest/dg/what-is.html


ML lens
-------
https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf
https://d1.awsstatic.com/whitepapers/machine-learning-in-financial-services-on-aws.pdf


DeepLens
--------
https://tutorialsdojo.com/aws-deeplens/
https://docs.aws.amazon.com/deeplens/latest/dg/what-is-deeplens.html


aws-random-cut-forest
----------------------
-> https://medium.com/@jiezhang_54502/predict-credit-card-fraud-by-using-aws-random-cut-forest-5a6ba460e65f

Deep Neural Networks for YouTube Recommendations -> https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf




==========================================================



Exam AI-102: Designing and Implementing a Microsoft Azure AI Solution
-> https://docs.microsoft.com/en-us/learn/certifications/exams/ai-102


===========================================================
Prep:
Extensive experience in Statistical and Machine Learning techniques like Regression (Linear/Logit/Gamma), Clustering (K-Means/Modes/Hier), Decision Trees, Text Mining and Natural Language Processing, Stochastic models, Bayesian Models, Markov Chains, Monte Carlo Simulations, Non-linear Time Series, Dynamic Programming and Optimization techniques, Design of Experiments, Neural Networks, Statistical Inference, Collaborative Filtering, Feature Engineering, etc.


Prior strong experience applying Time series method families like ARIMA, Exponential Smoothing, Decision Trees, Gradient Boosting, Random Forest, and Neural Networks for aggregate prediction and use of Recurrent Neural Networks for forecasting in several projects


=====================

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

============== NLP related top picks TODO ================
How to Develop Word-Based Neural Language Models in Python with Keras -> https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/
LSTM 
	-> Making Predictions with Sequences -> https://machinelearningmastery.com/sequence-prediction/
	-> A Gentle Introduction to LSTM Autoencoders -> https://machinelearningmastery.com/lstm-autoencoders/
	-> How to Develop a Seq2Seq Model for Neural Machine Translation in Keras -> https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/
	-> Follow links (right side)
	-> How to Develop an Encoder-Decoder Model for Sequence-to-Sequence Prediction in Keras -> https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/
	-> Difference Between Return Sequences and Return States for LSTMs in Keras -> https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/
	-> Data Preparation for Variable Length Input Sequences -> https://machinelearningmastery.com/data-preparation-variable-length-input-sequences-sequence-prediction/
	-> Sentiment Analysis with Naive Bayes and LSTM -> https://activewizards.com/blog/sentiment-analysis-with-naive-bayes-and-lstm/
	-> Sentiment Analysis using LSTM (Step-by-Step Tutorial) -> https://towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948

Deep Convolutional Neural Network for Sentiment Analysis (Text Classification) 
	-> https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/
	
Hands-On Speech Recognition Engine with Keras and Python
	-> https://fortes-arthur.medium.com/hands-on-speech-recognition-engine-with-keras-and-python-c60488ac53cd
		Dataset -> https://www.kaggle.com/c/tensorflow-speech-recognition-challenge
		Code -> https://github.com/arthurfortes/speech2text_keras
		
	-> Audio Deep Learning Made Simple: Automatic Speech Recognition (ASR), How it Works -> https://towardsdatascience.com/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706
	
	-> python-speech-recognition -> https://realpython.com/python-speech-recognition/

============== CV TODO ===========================
Image segmentation
	-> Computer Vision Tutorial: A Step-by-Step Introduction to Image Segmentation Techniques (Part 1) -> https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&utm_medium=computer-vision-implementing-mask-r-cnn-image-segmentation
	
	-> Image Segmentation Using Mask R-CNN -> https://towardsdatascience.com/image-segmentation-using-mask-r-cnn-8067560ed773
	-> Train Custom Dataset Mask RCNN -> https://towardsdatascience.com/train-custom-dataset-mask-rcnn-6407846598db
	
============== Time Series TODO ================
LSTM 
	->How to Develop LSTM Models for Time Series Forecasting -> https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/
ARIMA
	-> Weather forecasting with Machine Learning, using Python -> https://towardsdatascience.com/weather-forecasting-with-machine-learning-using-python-55e90c346647
		Dataset -> https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data?select=GlobalLandTemperaturesByMajorCity.csv

Anomaly (Isolation Forest)
	-> Anomaly Detection in Time Series: 2021 -> https://neptune.ai/blog/anomaly-detection-in-time-series
		Dataset -> https://www.kaggle.com/c/expedia-personalized-sort/data
	-> Anomaly Detection with Time Series Forecasting -> https://towardsdatascience.com/anomaly-detection-with-time-series-forecasting-c34c6d04b24a
	

https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/
https://analyticsindiamag.com/complete-guide-to-sarimax-in-python-for-time-series-modeling/
https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3	

============== Regular ML stuff TODO ===============
Sales Prediction using Python for Machine Learning -> https://hpriya206.medium.com/sales-prediction-using-python-for-machine-learning-6a76e4d63e71
	DataSet -> https://www.kaggle.com/shivan118/big-mart-sales-prediction-datasets
Weather forecast
	-> Predicting Weather Temperature Change Using Machine Learning Models -> https://medium.com/swlh/predicting-weather-temperature-change-using-machine-learning-models-4f98c8983d08
		Dataset -> https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data
	
	-> Weather forecasting with RNN in Python -> https://medium.com/analytics-vidhya/weather-forecasting-with-recurrent-neural-networks-1eaa057d70c3
		Dataset -> https://drive.google.com/drive/folders/12JTdHancAxquTuDxNJGwuKf-93I4cOGI?usp=sharing
	
	-> Using Machine Learning to Predict the Weather (LR and NN) -> https://github.com/amcquistan/WeatherPredictPythonML

Anomaly Detection (Isolation Forest)
		-> https://towardsdatascience.com/anomaly-detection-with-isolation-forest-visualization-23cd75c281e2
			Dataset -> ??
Linear Discriminant Analysis for Machine Learning
	-> https://machinelearningmastery.com/linear-discriminant-analysis-with-python/
	-> https://machinelearningmastery.com/linear-discriminant-analysis-for-machine-learning/

KNN-Imputation (handling missing values)
	-> https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/
	-> https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e

RCF
	-> Predict Credit Card Fraud by Using AWS Random Cut Forest -> https://medium.com/@jiezhang_54502/predict-credit-card-fraud-by-using-aws-random-cut-forest-5a6ba460e65f
		Dataset -> https://www.kaggle.com/mlg-ulb/creditcardfraud

NN
	-> https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/
	-> Building a Neural Network From Scratch Using Python (Part 1) -> https://heartbeat.fritz.ai/building-a-neural-network-from-scratch-using-python-part-1-6d399df8d432
		Dataset -> https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29

A/B Testing
	-> A/B Testing Design & Execution -> https://towardsdatascience.com/a-b-testing-design-execution-6cf9e27c6559
	-> A/B Testing : A Python Approach (Part 2) -> https://medium.com/analytics-vidhya/a-b-testing-a-python-approach-part-2-9958ed870a6f
		Dataset : Cookie-cat from Kaggle
	
============= Recommendation system TODO =====================
https://www.analyticsvidhya.com/blog/2020/11/create-your-own-movie-movie-recommendation-system/
https://towardsdatascience.com/how-to-build-a-movie-recommendation-system-67e321339109
	Dataset -> https://grouplens.org/datasets/movielens/
	
Restaurant recommendation system on Kaggle yelp dataset -> https://github.com/CateGitau/restaurant-recommendation-system/blob/main/notebooks/Recommendation_Systems.ipynb
https://categitau.medium.com/restaurant-recommender-system-eefd3226ed61


=========== Ranking Entities =============
How to Rank Entities with Multi-Criteria Decision Making Methods(MCDM) -> https://www.analyticsvidhya.com/blog/2020/09/how-to-rank-entities-with-multi-criteria-decision-making-methodsmcdm/

Ranking algorithms — know your multi-criteria decision solving techniques! -> https://towardsdatascience.com/ranking-algorithms-know-your-multi-criteria-decision-solving-techniques-20949198f23e

Text Summarization with Python -> https://medium.com/@umerfarooq_26378/text-summarization-in-python-76c0a41f0dc4

========== Semantic Search Engines ==============
On Making A Multilingual Search Engine -> https://medium.com/modern-nlp/on-making-a-multilingual-search-engine-9472a7c0dfa7

Cross-Lingual Similarity and Semantic Search Engine with Multilingual Universal Sentence Encoder -> https://www.tensorflow.org/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder

	
========== More ================
Auto Suggestions -> https://www.geeksforgeeks.org/autocomplete-input-suggestion-using-python-and-flask/
	




========================== Interview Questions ===============
- what is hypothesis testing ?
- what is p-value ?
- How to decide cut-off for p-value
- what is significance level and confidence level ?
- what is standard deviation ?
How to implement these 5 powerful probability distributions in Python -> https://bigdata-madesimple.com/how-to-implement-these-5-powerful-probability-distributions-in-python/

--- Drifts ---
- How to address data drift, concept drift
- concept drift -> https://neptune.ai/blog/concept-drift-best-practices
- Concept Drift and Model Decay in Machine Learning -> https://github.com/ashokc/Concept-Drift-and-Model-Decay
- Covariate Shift -> https://www.analyticsvidhya.com/blog/2017/07/covariate-shift-the-hidden-problem-of-real-world-data-science/


- chi-squared-test -> https://machinelearningmastery.com/chi-squared-test-for-machine-learning/
- A/B Testing -> https://www.analyticsvidhya.com/blog/2020/10/ab-testing-data-science/

- Normality test -> https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/
- data-normalization -> https://www.geeksforgeeks.org/data-normalization-with-pandas/

- Linear regression cost functions ? 
- RMSE, R2 why what ? why R2 prefer over RMSE 

- What is correlation coefficients 
- What is covariance ? 
- what is LR cost function  ? 
- what is log-loss ? -> https://www.youtube.com/watch?v=bhhJzlwbPcA

- How adam optimizer works ? -> https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/
- What is learning_rate ? -> Understand the Impact of Learning Rate on Neural Network Performance -> https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/

- SGD v/s GD (or Batch GD) -> https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/

-- Trees --
- What is DTC ?
- What is RFC ?
- How does DTC makes split (Jini index calculation) ?
- How sample selection happen for the trees for RFC (bootstrap sampling ? )
- Bagging v/s boosting
- What is entropy, information gain ? -> https://www.bogotobogo.com/python/scikit-learn/scikt_machine_learning_Decision_Tree_Learning_Informatioin_Gain_IG_Impurity_Entropy_Gini_Classification_Error.php
- gentle-introduction-gradient-boosting-algorithm-machine-learning -> https://machinelearningmastery.com/configure-gradient-boosting-algorithm/
- XBG loss funtions -> https://machinelearningmastery.com/xgboost-loss-functions/
- XGB hyperparameter tuning -> https://machinelearningmastery.com/configure-gradient-boosting-algorithm/
- Gradient Boosting with Scikit-Learn, XGBoost, LightGBM, and CatBoost -> https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/

--- evaluation ---
How to Use ROC Curves and Precision-Recall Curves for Classification in Python -> https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/
- ROC Curves summarize the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.
- Precision-Recall curves summarize the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.
- ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.
- Precision can be seen as a measure of quality, and recall as a measure of quantity. Higher precision means that an algorithm returns more relevant results than irrelevant ones, and high recall means that an algorithm returns most of the relevant results (whether or not irrelevant ones are also returned).


-- DL ---
- Cross-entropy -> https://machinelearningmastery.com/cross-entropy-for-machine-learning/
- How to choose loss function -> https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
- Loss and Loss Functions for Training Deep Learning Neural Networks -> https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/
- learning-rate How to Configure the Learning Rate When Training Deep Learning Neural Networks -> https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/
- What is Relu/Sigmoid/Tanh cost functions - aka activation functions -> https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/
- Why Relu prefers over Sigmoid (vanising gradients, Sigmoid ranges 0 to 0.25)
- What is the derivative of sigmoid function ? 0-0.25
- What is exploding gradients, why it happens (initialization of NN - normal, He normal etc what are the significance)
--> what-are-kernel-initializers-and-what-is-their-significance -> https://datascience.stackexchange.com/questions/37378/what-are-kernel-initializers-and-what-is-their-significance
- How to address these exploding gradients and vanising gradients ? -> https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/
https://machinelearningmastery.com/exploding-gradients-in-neural-networks/  -> follow links in this url below for Article section

- What is MaxPooling, AveragePooling - what does they do
- What is Dropout


---- model evaluation ----
- F1 score is the harmonic mean of Precision and Recall: = 2* ( (precision*recall) / (precision+recall) )
- Precision is the number of correctly identified positive results divided by the number of all positive results, including those not identified correctly. That is fraction of true positives among all predictive positives, precision = TP / (TP+FP)
- Recall is the number of correctly identified positive results divided by the number of all samples that should have been identified as positive. 
Also called TPR = TP / (TP+FN)
- Accuracy is the fraction of correct predictions. Large value indicates better predictive accuracy, accuracy = (TP+TN) / (TP+FN+FP+TN)
- F1 score provides a better measure of the incorrectly classified ones, than Accuracy metric since F1 score penalizes the extreme values









